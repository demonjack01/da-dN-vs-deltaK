{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import torch.utils.data as Data\n",
    "import optuna\n",
    "import optuna.trial\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_profiling as ppf\n",
    "data = pd.read_csv('./data/train_data.csv')\n",
    "# ppf.ProfileReport(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 分割训练集和测试集\n",
    "from torch import seed\n",
    "\n",
    "\n",
    "x = data.iloc[:, [0,2]].values\n",
    "y = data.iloc[:, 1].values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# 数据标准化\n",
    "ss1 = preprocessing.StandardScaler()\n",
    "x_train = ss1.fit_transform(x_train)\n",
    "x_test = ss1.transform(x_test)\n",
    "x_total=ss1.transform(x)\n",
    "\n",
    "\n",
    "y_mean = y_train.mean()\n",
    "y_std = y_train.std()\n",
    "y_train = (y_train-y_mean)/y_std\n",
    "y_test=(y_test-y_mean)/y_std\n",
    "\n",
    "# numpy转tensor\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train).float().view(-1,1)\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test).float().view(-1,1)\n",
    "x_total=torch.from_numpy(x_total).float()\n",
    "\n",
    "# batch_size = 64\n",
    "torch_dataset = Data.TensorDataset(x_train, y_train) \n",
    "loader = Data.DataLoader(dataset=torch_dataset,batch_size=len(x),\n",
    "            shuffle=True) \n",
    "\n",
    "# print(next(iter(loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LR(nn.Module):\n",
    "\n",
    "    def __init__(self,trial):\n",
    "        super(LR, self).__init__()\n",
    "        fc1_out=trial.suggest_int(\"fc1_out\", 16, 128,16)\n",
    "        self.fc1 = nn.Linear(2, fc1_out)\n",
    "        fc2_out=trial.suggest_int(\"fc2_out\",16,128,16)\n",
    "        self.fc2 = nn.Linear(fc1_out, fc2_out)\n",
    "        fc3_out=trial.suggest_int(\"fc3_out\",16,128,16)\n",
    "        self.fc3 = nn.Linear(fc2_out, fc3_out)\n",
    "        self.fc4 = nn.Linear(fc3_out, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x=torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    net=LR(trial)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"Adadelta\",\"Adagrad\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1,log=True)\n",
    "    weight_decay=trial.suggest_float(\"weight_decay\",1e-3,1e-1,log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(net.parameters(), lr=lr,weight_decay=weight_decay) \n",
    "\n",
    "    epochs_list=[]\n",
    "    train_loss_list=[]\n",
    "    test_error_list=[]\n",
    "    for e in range(epochs):\n",
    "        epochs_list.append(e)\n",
    "        net.train()\n",
    "        for i, (batch_x, batch_y) in enumerate(loader):\n",
    "            y_hat = net(batch_x)\n",
    "    #         print(y_hat.shape)\n",
    "            \n",
    "            loss = criterion(y_hat, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred_train= net(x_train)\n",
    "            loss = criterion(y_pred_train, y_train)\n",
    "            train_loss_list.append(loss.item())\n",
    "            \n",
    "            y_pred_test = net(x_test)\n",
    "            error = criterion(y_pred_test, y_test)\n",
    "            test_error_list.append(error.item())\n",
    "            # if (e+1)%50==0:\n",
    "            #     print(\"Epoch:{}, trainLoss:{}，testLoss:{}\".format(e+1,loss.item(),error.item()))\n",
    "\n",
    "        trial.report(error,e)\n",
    "\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-24 22:17:20,243]\u001b[0m A new study created in memory with name: no-name-f68b4c8f-1da1-488e-aca5-a3784d3a587c\u001b[0m\n",
      "\u001b[32m[I 2022-10-24 22:17:30,720]\u001b[0m Trial 0 finished with value: 0.05747666954994202 and parameters: {'fc1_out': 32, 'fc2_out': 96, 'fc3_out': 64, 'optimizer': 'Adam', 'lr': 0.0007837054420502013, 'weight_decay': 0.0036147272908536687}. Best is trial 0 with value: 0.05747666954994202.\u001b[0m\n",
      "\u001b[33m[W 2022-10-24 22:17:32,240]\u001b[0m Trial 1 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\86189\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\86189\\AppData\\Local\\Temp\\ipykernel_26900\\3524078032.py\", line 21, in objective\n",
      "    loss.backward()\n",
      "  File \"c:\\Users\\86189\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\torch\\_tensor.py\", line 396, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"c:\\Users\\86189\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 173, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\86189\\Desktop\\大创及项目\\代码\\线性层2to1超参数优化.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/86189/Desktop/%E5%A4%A7%E5%88%9B%E5%8F%8A%E9%A1%B9%E7%9B%AE/%E4%BB%A3%E7%A0%81/%E7%BA%BF%E6%80%A7%E5%B1%822to1%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/86189/Desktop/%E5%A4%A7%E5%88%9B%E5%8F%8A%E9%A1%B9%E7%9B%AE/%E4%BB%A3%E7%A0%81/%E7%BA%BF%E6%80%A7%E5%B1%822to1%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/86189/Desktop/%E5%A4%A7%E5%88%9B%E5%8F%8A%E9%A1%B9%E7%9B%AE/%E4%BB%A3%E7%A0%81/%E7%BA%BF%E6%80%A7%E5%B1%822to1%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m trial \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_trial\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/86189/Desktop/%E5%A4%A7%E5%88%9B%E5%8F%8A%E9%A1%B9%E7%9B%AE/%E4%BB%A3%E7%A0%81/%E7%BA%BF%E6%80%A7%E5%B1%822to1%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAccuracy: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(trial\u001b[39m.\u001b[39mvalue))\n",
      "File \u001b[1;32mc:\\Users\\86189\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\optuna\\study\\study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[0;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m     _optimize(\n\u001b[0;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[0;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    429\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\86189\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\86189\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\86189\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\optuna\\study\\_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    233\u001b[0m ):\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\86189\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "\u001b[1;32mc:\\Users\\86189\\Desktop\\大创及项目\\代码\\线性层2to1超参数优化.ipynb Cell 7\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/86189/Desktop/%E5%A4%A7%E5%88%9B%E5%8F%8A%E9%A1%B9%E7%9B%AE/%E4%BB%A3%E7%A0%81/%E7%BA%BF%E6%80%A7%E5%B1%822to1%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96.ipynb#W6sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(y_hat, batch_y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/86189/Desktop/%E5%A4%A7%E5%88%9B%E5%8F%8A%E9%A1%B9%E7%9B%AE/%E4%BB%A3%E7%A0%81/%E7%BA%BF%E6%80%A7%E5%B1%822to1%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96.ipynb#W6sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/86189/Desktop/%E5%A4%A7%E5%88%9B%E5%8F%8A%E9%A1%B9%E7%9B%AE/%E4%BB%A3%E7%A0%81/%E7%BA%BF%E6%80%A7%E5%B1%822to1%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96.ipynb#W6sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/86189/Desktop/%E5%A4%A7%E5%88%9B%E5%8F%8A%E9%A1%B9%E7%9B%AE/%E4%BB%A3%E7%A0%81/%E7%BA%BF%E6%80%A7%E5%B1%822to1%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96.ipynb#W6sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/86189/Desktop/%E5%A4%A7%E5%88%9B%E5%8F%8A%E9%A1%B9%E7%9B%AE/%E4%BB%A3%E7%A0%81/%E7%BA%BF%E6%80%A7%E5%B1%822to1%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m net\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\86189\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\86189\\anaconda3\\envs\\pythonProject\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "trial = study.best_trial\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\86189\\Desktop\\大创及项目\\代码\\线性层2to1超参数优化.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/86189/Desktop/%E5%A4%A7%E5%88%9B%E5%8F%8A%E9%A1%B9%E7%9B%AE/%E4%BB%A3%E7%A0%81/%E7%BA%BF%E6%80%A7%E5%B1%822to1%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trial\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trial' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data=pd.read_csv('./data/test_data.csv').values\n",
    "valid_data_target=valid_data[:,[0,2]]\n",
    "valid_data_y=valid_data[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def valid(trial):\n",
    "    net=LR(trial)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"Adadelta\",\"Adagrad\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1,log=True)\n",
    "    weight_decay=trial.suggest_float(\"weight_decay\",1e-3,1e-1,log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(net.parameters(), lr=lr,weight_decay=weight_decay) \n",
    "\n",
    "    epochs_list=[]\n",
    "    train_loss_list=[]\n",
    "    test_error_list=[]\n",
    "    for e in range(epochs):\n",
    "        epochs_list.append(e)\n",
    "        net.train()\n",
    "        for i, (batch_x, batch_y) in enumerate(loader):\n",
    "            y_hat = net(batch_x)\n",
    "    #         print(y_hat.shape)\n",
    "            \n",
    "            loss = criterion(y_hat, batch_y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred_train= net(x_train)\n",
    "            loss = criterion(y_pred_train, y_train)\n",
    "            train_loss_list.append(loss.item())\n",
    "            \n",
    "            y_pred_test = net(x_test)\n",
    "            error = criterion(y_pred_test, y_test)\n",
    "            test_error_list.append(error.item())\n",
    "            if (e+1)%50==0:\n",
    "                print(\"Epoch:{}, trainLoss:{}，testLoss:{}\".format(e+1,loss.item(),error.item()))\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.xlabel(\"Training epochs\")\n",
    "    plt.ylabel(\"error\")\n",
    "    plt.grid()\n",
    "    plt.plot(epochs_list, train_loss_list, '.-', color=\"r\",\n",
    "                    label=\"train_loss_\")\n",
    "    plt.plot(epochs_list, test_error_list, '.-', color=\"g\",\n",
    "                    label=\"test_error\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    \n",
    "    net.eval()\n",
    "    x_valid=ss1.transform(valid_data_target)\n",
    "    x_valid = torch.from_numpy(x_valid).float()\n",
    "\n",
    "    y_pred=net(x_total)\n",
    "    y_pred=y_pred.data.numpy()\n",
    "    y_pred=y_pred*y_std+y_mean\n",
    "\n",
    "    y_pred_valid=net(x_valid)\n",
    "    y_pred_valid=y_pred_valid.data.numpy()\n",
    "    y_pred_valid=y_pred_valid*y_std+y_mean\n",
    "\n",
    "    x_axis=data.iloc[:,0].values\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "    plt.scatter(x_axis,y_pred,s=50,c=\"b\")\n",
    "    plt.scatter(x_axis,y,s=50,c=\"g\")\n",
    "\n",
    "    x_axis_valid=valid_data[:,0]\n",
    "    plt.scatter(x_axis_valid,y_pred_valid,s=50,c=\"c\")\n",
    "    plt.scatter(x_axis_valid,valid_data_y,s=50,c=\"r\")\n",
    "    plt.grid()\n",
    "    plt.xlim(0,2)\n",
    "    plt.ylim(-13,-7)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\86189\\Desktop\\大创及项目\\代码\\线性层2to1超参数优化.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/86189/Desktop/%E5%A4%A7%E5%88%9B%E5%8F%8A%E9%A1%B9%E7%9B%AE/%E4%BB%A3%E7%A0%81/%E7%BA%BF%E6%80%A7%E5%B1%822to1%E8%B6%85%E5%8F%82%E6%95%B0%E4%BC%98%E5%8C%96.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m valid(trial)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trial' is not defined"
     ]
    }
   ],
   "source": [
    "valid(trial)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pythonProject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "031490cb4fb8a925db20958c57cafe119126066026c78a34d7b5ac309ed8eb51"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
